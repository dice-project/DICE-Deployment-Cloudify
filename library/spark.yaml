# Apache Spark
# ============

inputs:

  spark.1.tarball:
    default: "http://d3kbcqa49mib13.cloudfront.net/spark-1.6.2-bin-hadoop2.6.tgz"
  spark.1.checksum:
    default: "bddeccec0fb8ac9491cbb4e320467e9263bcc1caf9b45466164f8ae2d97de710"

  spark.2.tarball:
    default: "http://d3kbcqa49mib13.cloudfront.net/spark-2.2.0-bin-hadoop2.7.tgz"
  spark.2.checksum:
    default: "97fd2cc58e08975d9c4e4ffa8d7f8012c0ac2792bcd9945ce2a561cf937aebcc"


dsl_definitions:

  - &java_attributes
    java:
      jdk_version:    { get_input: java_version }
      install_flavor: { get_input: java_flavor  }

  - &spark_tarballs
    "1.6":
      tarball:  { get_input: spark.1.tarball  }
      checksum: { get_input: spark.1.checksum }
    "2.0":
      tarball:  { get_input: spark.2.tarball  }
      checksum: { get_input: spark.2.checksum }

  - &spark_master_attributes
    <<: *java_attributes
    spark:
      <<: *spark_tarballs
      type: master

  - &spark_worker_attributes
    <<: *java_attributes
    spark:
      <<: *spark_tarballs
      type: worker


node_types:

  dice.components.spark.Base:
    derived_from: dice.chef.SoftwareComponent
    properties:
      create_runlist:
        default:
          - recipe[apt::default]
          - recipe[dice_common::default]
          - recipe[java::default]
          - recipe[spark::default]
          - recipe[dmon_agent::default]
          - recipe[dmon_agent::collectd]
      configure_runlist:
        default:
          - recipe[spark::configure]
          - recipe[dmon_agent::spark]
      start_runlist:
        default:
          - recipe[spark::start]
      stop_runlist:
        default:
          - recipe[dmon_agent::remove_node]

  dice.components.spark.Master:
    derived_from: dice.components.spark.Base
    properties:
      chef_attributes:
        default: *spark_master_attributes

  dice.components.spark.Worker:
    derived_from: dice.components.spark.Base
    properties:
      chef_attributes:
        default: *spark_worker_attributes

  dice.components.spark.Application:
    derived_from: dice.LogicalNode
    properties:
      jar:
        description: >-
          Location of application's jar file. If this is relative path, file
          is assumed to be part of the blueprint package. If this URL, file
          will be downloaded.
      class:
        description: Class that should be executed.
      name:
        description: Name of the application that is being submitted.
      args:
        description: >-
          Arguments that should be passed to application on submission. Note
          that when jar is executed, first argument is always application
          name.  Arguments in this property are passed as an additional
          arguments after name.
        default: []
    interfaces:
      cloudify.interfaces.lifecycle:
        start:
          implementation: dice.dice_plugin.tasks.spark.submit
          inputs:
            jar:   { default: { get_property: [ SELF, jar   ] } }
            name:  { default: { get_property: [ SELF, name  ] } }
            klass: { default: { get_property: [ SELF, class ] } }
            args:  { default: { get_property: [ SELF, args  ] } }


  # Firewall rules
  dice.firewall_rules.spark.Master:
    derived_from: dice.firewall_rules.Base
    properties:
      rules:
        default:
          - ip_prefix: 0.0.0.0/0
            protocol: tcp
            port: 6066
          - ip_prefix: 0.0.0.0/0
            protocol: tcp
            from_port: 7077
            to_port: 7080
          - ip_prefix: 0.0.0.0/0
            protocol: tcp
            port: 8080

  dice.firewall_rules.spark.Worker:
    derived_from: dice.firewall_rules.Base
    properties:
      rules:
        default:
          - ip_prefix: 0.0.0.0/0
            protocol: tcp
            from_port: 7078
            to_port: 7080


relationships:

  dice.relationships.spark.ConnectedToMaster:
    derived_from: cloudify.relationships.connected_to
    source_interfaces:
      cloudify.interfaces.relationship_lifecycle:
        preconfigure:
          implementation: dice.dice_plugin.tasks.base.copy_ip_from_target
          inputs:
            property: { default: master_ip }

  dice.relationships.spark.SubmittedBy:
    derived_from: cloudify.relationships.contained_in
    properties:
      connection_type: { default: all_to_one }
